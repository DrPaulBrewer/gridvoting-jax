# Changelog

All notable changes to this project will be documented in this file. This file and most of the code changes are AI generated by Antigravity, an AI coding assistant created by Google DeepMind's Advanced Agentic Coding team.  This is a private project and no association with Google or Alphabet Inc. is implied.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),

## [Unreleased]


## [0.7.0] - 2025-12-21

### Changed - BREAKING CHANGE

- **Removed `computeNow` parameter from `MarkovChain.__init__`**: The `computeNow` parameter has been completely removed.
  - **Rationale**: The default `computeNow=True` behavior caused a critical bug where all solver configurations incorrectly triggered `full_matrix_inversion` during initialization, preventing efficient solvers (`power_method`, `gmres`) from running and causing incorrect memory error messages.
  - **Migration**: Users must now explicitly call `find_unique_stationary_distribution()` after creating a `MarkovChain` instance if they want to compute the stationary distribution.
  - **Example**:
    ```python
    # Before (v0.6.0 and earlier):
    mc = gv.MarkovChain(P, computeNow=True)
    
    # After (v0.7.0+):
    mc = gv.MarkovChain(P)
    mc.find_unique_stationary_distribution()
    ```
  - **Impact**: `VotingModel.analyze()` is unaffected and continues to work correctly. Only direct `MarkovChain` usage requires updates.

### Added

- **GPU Memory Allocator**: Automatically sets `TF_GPU_ALLOCATOR=cuda_malloc_async` for GPU devices to reduce memory fragmentation issues.
  - **Rationale**: Addresses JAX BFC allocator fragmentation that prevented large grids (g=60+) from running on GPUs with sufficient VRAM.
  - **Behavior**: Only sets if not already defined in environment; can be overridden by user.

### Fixed

- **Solver Selection Bug**: Fixed critical bug where `MarkovChain` initialization always ran `full_matrix_inversion` solver regardless of the requested solver in `VotingModel.analyze()`.
- **Memory Error Messages**: Error messages now correctly reference the actual solver being used instead of always showing `'full_matrix_inversion'`.
- **Large Grid Support**: Enables `g=80` grids to run successfully on CPU with `power_method` and `gmres_matrix_inversion` solvers.

## [0.5.1] - 2025-12-20

### Fixed
- **Test Failure**: Fixed `test_solver_invalid_arg` in `test_solvers.py` which failed to raise `ValueError` because the test setup created an accidental Core. Updated test to use a Condorcet Cycle (no Core).

## [0.5.0] - 2025-12-20

### Added
- **Alternative Solvers**: Introduced `gmres_matrix_inversion` (memory-efficient), `power_method` (iterative), and `grid_upscaling` (multi-grid) solvers for `MarkovChain`.
- **Large Grid Support**: Solved OOM issues on large grids (e.g., g=80) using GMRES and batched processing.
- **Benchmark Expansion**: Updated `osf_comparison.py` to support all solvers, floating point precision reporting, and auto-skipping of OOM-prone configurations.
- **Float64 Auto-detection**: `core.py` now respects `GV_ENABLE_FLOAT64` or `JAX_ENABLE_X64` environment variables.

### Changed
- `MarkovChain.find_unique_stationary_distribution` now accepts `solver` and `initial_guess`.
- `VotingModel.analyze` now accepts `solver` and `grid` arguments. - 2025-12-20

### Fixed
- **Memory Optimization**: Implemented batched execution for transition matrix calculation. Resolves Out-of-Memory (OOM) errors for large grids (e.g., g>=60). Memory complexity reduced from O(V*N^2) to O(V*N*B), enabling simulations with g=80+ on standard hardware.

## [0.4.0] - 2025-12-20

### Added
- **Modularization**: Codebase split into `core`, `spatial`, `dynamics`, and `datasets` submodules.
- **Datasets**: New `datasets` module for managing data downloads.
- **Configuration**: Centralized configuration and tolerances in `core`.

### Changed
- **Facade**: `__init__.py` now acts as a facade, exporting the public API from submodules.
- **Internal**: `_move_neg_prob_to_max` is no longer exported in the public API.

## [0.3.3] - 2025-12-20

### Changed - BREAKING CHANGE
- **Renamed Class**: `MarkovChainCPUGPU` is now `MarkovChain`. The old name has been removed.

### Documentation
- **README**: Updated numerical accuracy section to use more cautious language regarding Float32 precision limitations.

## [0.3.2] - 2025-12-20

### Fixed
- **Grid.extremes()**: Updated logic to correctly calculate min/max over the entire array `z` while restricting returned points to those valid in the `valid` mask.
- **Helper Assertions**: Fixed `assert_valid_transition_matrix` and `assert_zero_diagonal_int_matrix` to correctly check for square matrices `(rows, rows)`.
- **MarkovChainCPUGPU**: 
  - Increased negative probability tolerance in `solve_for_unit_eigenvector` from -2e-7 to -1e-5.
  - Refactored to use new `evolve()` method for cleaner code.
  - Fixed indentation error in `evolve()` method.

## [0.6.0] - 2025-12-20
### Added
- **Refactored Solvers**: Removed `g>=60` limit for `full_matrix_inversion`.
- **Memory Safeguards**: Added `get_available_memory_bytes` to check system memory (Linux/Mac/JAX) and prevent OOM errors before they crash the kernel.
- **Adaptive Timeout**: Added `timeout` parameter (default 10s) to `power_method` solver with adaptive checking.

## [0.5.1] - 2025-12-19
### Fixed
- Patched GitHub Actions workflow for Docker publishing to support manual triggers and fix casing issues.

## [0.3.0] - 2025-12-19

### Added
- Dockerfiles for CPU (`Dockerfiles/Dockerfile.cpu`) and GPU (`Dockerfiles/Dockerfile.gpu`) images with baked-in OSF benchmark data.
- GitHub Actions workflow (`.github/workflows/docker-publish.yml`) to auto-publish images to GHCR on release.
- `run_osf_benchmark` entrypoint scripts in Docker images for easy execution.
- Configurable OSF cache location via `GV_OSF_CACHE_DIR` environment variable.
- Replaced `test_docker_osf.sh` with an optimized version that uses pre-built GHCR images instead of building locally, significantly reducing runtime.

### Changed

## [0.2.0] - 2025-12-19

### Added
- **OSF Replication Data Benchmark**: Added verification benchmark that compares library output against original A100 GPU replication data from OSF repository (`osf_comparison` benchmark).
- **Automatic Data Caching**: New benchmark automatically downloads and caches 8 reference stationary distribution datasets to `/tmp/gridvoting_osf_cache`.
- **L1 Norm Comparison**: Implemented L1 norm metric for rigorous verification of stationary distributions against ground truth.
- **Single-Function Benchmark API**: Exposed `gv.benchmarks.run_comparison_report()` for easy one-line verification.
- **Google Colab Support**: Added dedicated instructions and code blocks for running benchmarks in Google Colab.
- **OSF Documentation**: Added `OSF_COMPLETE_DATASET.md` detailing the downloaded reference data.
- **Docker Verification Script**: Added `test_docker_osf.sh` for comprehensive CPU/GPU testing.
  - Automatically detects GPU availability (`nvidia-smi`)
  - Runs 4 benchmark configurations: CPU (Float32/Float64) and GPU (Float32/Float64) if hardware available
  - Uses isolated Docker environments (Ubuntu 24.04 for CPU, NVIDIA CUDA 12.3.1 for GPU)
  - Features broken dependency protection (checks for missing NVIDIA Container Toolkit) and output suppression for cleaner logs

## [0.1.0] - 2025-12-18

### Changed - BREAKING CHANGE

- **Environment variable renamed**: Changed CPU-only mode trigger from `NO_GPU=1` to `GV_FORCE_CPU=1`
  - **Rationale**: Clearer, more descriptive naming with project-specific prefix (`GV_` for GridVoting)
  - **Migration**: Users must update scripts from `NO_GPU=1` to `GV_FORCE_CPU=1`
  - **Old variable no longer works**: This is a hard cutover; `NO_GPU=1` will not force CPU mode
- **Updated warning message**: CPU-only mode now displays `"GV_FORCE_CPU=1: JAX forced to CPU-only mode"`
- **Fixed typo in property name**: `MarkovChainCPUGPU.has_unique_stationary_distibution` â†’ `MarkovChainCPUGPU.has_unique_stationary_distribution`
  - **Rationale**: Correct spelling of "distribution" (was missing 'r')
  - **Migration**: Update any code accessing this property to use the correct spelling
- **Version bump**: Incremented to 0.1.0 to reflect breaking changes
- **Converted NumPy to JAX in non-plotting code**: Replaced `np.asarray`, `np.dot`, and `np.array` with JAX equivalents (`jnp.asarray`, `jnp.dot`, `jnp.array`) in core computational functions
  - Updated `Grid.extremes()` comment for clarity
  - Updated `Grid.spatial_utilities()` to use `jnp.asarray` for voter ideal points
  - Updated `VotingModel.E_ð¿()` to use `jnp.dot` for expected value calculation
  - Updated `CondorcetCycle.__init__()` to use `jnp.array` for utility functions
- **Migrated to chex for assertions**: Replaced NumPy testing assertions with JAX-compatible chex assertions
  - **Rationale**: Enable JIT-compatible assertions, better integration with JAX ecosystem
  - **Source code**: Updated `assert_valid_transition_matrix()` and `assert_zero_diagonal_int_matrix()` to use chex; now expect only JAX arrays (removed "or numpy" from docstrings)
  - **Tests**: Replaced all `np.testing.assert_*` calls with `chex.assert_*` equivalents across 4 test files
  - **New dependency**: Added `chex>=0.1.0` to requirements
- **Removed unnecessary NumPy usage in non-plotting code**: Replaced remaining NumPy functions with JAX equivalents
  - **Rationale**: Consistency with JAX-first approach, avoid unnecessary array conversions, better JIT compatibility
  - **VotingModel.analyze()**: Removed `np.array()` conversions (already JAX arrays), use `jnp.any()`
  - **VotingModel.what_beats()** and **what_is_beaten_by()**: Removed `np.array()` conversions, use JAX immutable updates
  - **VotingModel.summarize_in_context()**: Replaced `np.full()`, `np.cov()`, `np.log2()` with `jnp.full()`, `jnp.cov()`, `jnp.log2()`
  - **Breaking change**: These methods now return JAX arrays instead of NumPy arrays
- **Removed float32 type casts and added float64 support**: Removed explicit `float32` dtype specifications to allow flexible precision
  - **Rationale**: Let JAX infer dtype, support both float32 (default) and float64 (via `enable_float64()`)
  - **New function**: Added `enable_float64()` to enable 64-bit precision globally (see https://docs.jax.dev/en/latest/default_dtypes.html)
  - **Locations**: `MarkovChainCPUGPU.solve_for_unit_eigenvector()` (3 casts), `VotingModel._get_transition_matrix()` (2 casts)
  - **Tolerance**: Updated documentation to reflect 6 decimal places for float32, 10 for float64
  - **Non-breaking**: Default behavior unchanged (still uses float32)

### Changed - 2025-12-17

- **Refactored `solve_for_unit_eigenvector()` method**: Extracted negative probability correction logic into reusable helper function
- **Created `_move_neg_prob_to_max()` helper function**: JIT-compiled pure function that redistributes mass from negative components to maximum-value indices
- **Fixed mass redistribution bug**: Mass now distributed equally among **all** indices sharing the maximum value (within TOLERANCE), not just a single index
- **Removed diagnostic warnings**: Eliminated 4 unnecessary warnings from `solve_for_unit_eigenvector()` while preserving exception-related warnings
- **JAX JIT compatibility**: Implemented using `jnp.where()` instead of boolean indexing to ensure JIT compilation compatibility
- **Used TOLERANCE constant**: Applied module-level `TOLERANCE` (5e-5) for float32-compatible floating-point comparisons

### Technical Details

- Helper function uses immutable JAX operations for all array manipulations
- Correctly handles edge case where multiple indices have identical maximum values
- Cleaner separation of concerns: negative component correction isolated from eigenvector solving
- All 23 tests pass (100% success rate)
- Verified with NumPy 2.3.5 and JAX 0.4.20+ in isolated Docker environment

- **Created benchmarks submodule**: Moved standalone `benchmarks/` directory into package as `gridvoting_jax.benchmarks`
- **Added `benchmarks.performance()` function**: Accessible via `gv.benchmarks.performance()` for running performance benchmarks
- **Flexible output format**: `performance(dict=True)` returns results dictionary; `performance()` (default) prints formatted output
- **Removed unused NumPy import**: Eliminated unnecessary `import numpy as np` from benchmark code
- **Deleted standalone benchmarks directory**: Cleaned up project structure by removing redundant `benchmarks/` directory
- **Added benchmark test**: Created `test_benchmarks.py` to verify submodule functionality
- **Marked benchmark test as slow**: Added `@pytest.mark.slow` decorator to allow skipping long-running benchmark tests
- **Updated GitHub workflows**: Modified CI workflows to skip slow tests with `-m "not slow"` for faster CI runs

### Technical Details

- Benchmarks submodule uses relative imports from parent package
- Function returns structured dictionary with device info, JAX version, and per-test results
- Supports future expansion with additional benchmark functions
- All 23 tests pass (100% success rate) including new benchmark test
- Verified with NumPy 2.3.5 and JAX 0.4.20+ in isolated Docker environment


- **Grid class fully migrated to JAX arrays**: All Grid properties (`x`, `y`, `points`, `boundary`) now use `jnp.array` instead of `np.array`
- **Removed all assert statements from Grid class**: Eliminated 12 runtime assertions; JAX operations provide natural error handling for shape mismatches
- **Replaced barycentric triangle algorithm with cross-product method**: Implemented simpler, more robust half-plane test for `within_triangle()` using cross products
- **Added `_is_in_triangle_single()` helper function**: JIT-compiled cross-product triangle containment test with epsilon tolerance for edge/vertex cases
- **Vectorized triangle testing**: Used `jax.vmap` to efficiently apply triangle test across all grid points
- **Updated `embedding()` method**: Now uses JAX immutable update pattern (`.at[].set()`) instead of in-place assignment
- **Updated `extremes()` method**: Converted to use `jnp.full` and `jnp.abs` for JAX compatibility
- **Enhanced `plot()` method**: Automatically converts JAX arrays to NumPy for matplotlib compatibility
- **Updated test suite**: Converted test constants to `jnp.array` and replaced `np.testing.assert_array_equal` with `jnp.array_equal`

### Technical Details

- Cross-product algorithm based on [Stack Overflow answer](https://stackoverflow.com/a/2049593/103081) by Kornel Kisielewicz
- Epsilon tolerance of 1e-10 for robust edge/vertex handling in triangle containment
- All Grid methods now return JAX arrays (breaking change from NumPy arrays)
- Functional programming paradigm: no in-place modifications, immutable updates only
- All 22 tests pass (100% success rate)
- Verified with NumPy 2.3.5 and JAX 0.4.20+ in isolated Docker environment

### Changed - 2025-12-16

- **Removed pandas dependency**: Eliminated pandas from requirements; replaced `pd.Series().plot()` and `pd.DataFrame()` calls with direct matplotlib plotting
- **Removed scipy dependency**: Eliminated scipy from requirements; replaced `scipy.spatial.distance.cdist` with custom JAX implementations
- **Implemented JAX distance functions**: Added JIT-compiled `dist_sqeuclidean()` and `dist_manhattan()` functions for improved performance
- **Eliminated xp abstraction pattern**: Removed `xp` variable; now use `np` explicitly for NumPy operations and `jnp` explicitly for JAX operations
- **Removed diagnostic plotting code**: Removed power method diagnostics plotting that referenced non-existent attributes
- **Updated Grid methods**: Modified `spatial_utilities()` and `within_disk()` to use JAX distance functions with support for 'sqeuclidean' and 'manhattan' metrics
- **Updated test files**: Removed xp references from all test files; tests now import `jax.numpy as jnp` directly where needed

### Technical Details

- All `xp.asnumpy()` calls replaced with `np.array()`
- Distance calculations now use `@jax.jit` decorator for compilation optimization
- Maintained full backward compatibility - all 22 tests pass
- Verified with NumPy 2.3.5 and JAX 0.4.20+ in isolated Docker environment

